{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ast\n",
    "from pycountry_convert import country_alpha2_to_continent_code, country_name_to_country_alpha2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(table_name):\n",
    "    try:\n",
    "        conn = sqlite3.connect('/Users/tristannisbet/Documents/travel_app/places.db')\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Error durring connection: ', str(e))\n",
    "    \n",
    "    sql = \"\"\"select * from {}\"\"\".format(table_name)\n",
    "    df = pd.read_sql_query(sql, conn)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main call to create df for all food entries and city\n",
    "def cityFoodMain():\n",
    "    all_price = createFoodDf()\n",
    "    all_price_ = cleaningNullsCity(all_price)\n",
    "    food_city = addNanRowCity(all_price_)\n",
    "    final_food_city = selectColumns(food_city)\n",
    "    \n",
    "    \n",
    "    return final_food_city\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 called\n",
    "def createFoodDf():\n",
    "    one = get_df('restaurants_one')\n",
    "    two = get_df('restaurants_two')\n",
    "    three = get_df('restaurants_three')\n",
    "    four = get_df('restaurants_four')\n",
    "    top_rest = get_df('restaurants')\n",
    "    \n",
    "    all_price = pd.concat([one, two, three, four, top_rest], axis =0)\n",
    "    return(all_price)\n",
    "\n",
    "\n",
    "#2 called\n",
    "def cleaningNullsCity(restaurants_all):\n",
    "    \n",
    "    restaurants_all['id'] = pd.to_numeric(restaurants_all.id)\n",
    "    restaurants_all['price_level'] = restaurants_all['price_level'].fillna(restaurants_all.groupby('city')['price_level'].transform('mean'))\n",
    "    restaurants_all.fillna(2.0, inplace=True)\n",
    "    #do I need this?\n",
    "    restaurants_all['price_level'] = restaurants_all['price_level'].astype(int)\n",
    "    \n",
    "    city_food = toCityLevel(restaurants_all)\n",
    "    city_food.drop(columns = ['avg_price'], inplace=True)\n",
    "    city_food.fillna(0, inplace=True)\n",
    "    \n",
    "    return city_food\n",
    "\n",
    "\n",
    "#3\n",
    "def toCityLevel(df):\n",
    "    city_df = df.groupby(['country', 'city', 'id', 'price_level'])['name'].count().to_frame()\n",
    "    price_level = city_df.pivot_table(index=['country', 'city', 'id'], columns='price_level', values='name', aggfunc='first')\n",
    "    price_level['avg_price'] = df.groupby(['country', 'city', 'id'])['price_level'].mean()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    return price_level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#4 called\n",
    "def addNanRowCity(food_df):\n",
    "    food_df.reset_index(inplace=True)\n",
    "    nan_row = {'country' : None, 'city': 'Zx', 'id': 200, 1.0: 0, 2.0: 0, 3.0: 0, 4.0: 0}\n",
    "    food_df = food_df.append(nan_row, ignore_index=True)\n",
    "    \n",
    "    global food_new \n",
    "    food_new = labelEncodeCity(food_df)\n",
    "    food_new = food_new.drop(food_new[food_new.id == 200].index)\n",
    "    \n",
    "    return food_new\n",
    "\n",
    "\n",
    "\n",
    "# You might need to return both food and food_new. Food has city/country names\n",
    "\n",
    "#6\n",
    "def buildLabelEncoder():\n",
    "    \n",
    "    cities = get_df('cities')\n",
    "    new_row = {'id': 200, 'city': 'Zx', 'country': 'None'}\n",
    "    cities = cities.append(new_row, ignore_index=True)\n",
    "    \n",
    "    le = pp.LabelEncoder()\n",
    "    le.fit(cities.city)\n",
    "    \n",
    "    return le\n",
    "  \n",
    " # 5    \n",
    "def labelEncodeCity(food_df):\n",
    "    \n",
    "    le = buildLabelEncoder()\n",
    "    food_df['label_id'] = le.transform(food_df.city)\n",
    "    \n",
    "    return food_df\n",
    "\n",
    "# 7\n",
    "def selectColumns(food_df):\n",
    "    \n",
    "    food_df = food_df.drop(food_df[food_df.id == 200].index)\n",
    "    food_city = food_df[['label_id', 1.0, 2.0, 3.0, 4.0]].copy()\n",
    "    food_city.sort_values('label_id', inplace=True)\n",
    "    food_city.set_index('label_id', inplace=True)\n",
    "    \n",
    "    return food_city\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will pull survey data from database and select only food columns\n",
    "def createFoodUserDf():\n",
    "    survey = get_df('survey_response')\n",
    "    #survey = total.copy()\n",
    "    food_user = survey[['food_one', 'food_two', 'food_three', 'food_four']]\n",
    "    \n",
    "    return food_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters: city/user data all numeric. \n",
    "\n",
    "# sim_city_food is similarity matrix for all cities and food data\n",
    "# sim_user_food is similarity matrix for all user and food data\n",
    "\n",
    "# cosine_sim_food is similarit matrix for all usersXcities (153x138)\n",
    "def simScore(city, user):\n",
    "\n",
    "    normalized_city = pd.DataFrame(pp.normalize(city))    \n",
    "    normalized_user = pd.DataFrame(pp.normalize(user))\n",
    "\n",
    "\n",
    "    sim_city = pd.DataFrame(cosine_similarity(normalized_city))\n",
    "    sim_user = pd.DataFrame(cosine_similarity(normalized_user))\n",
    "    \n",
    "    cosine_sim_food = pd.DataFrame(cosine_similarity(normalized_user, normalized_city))\n",
    "\n",
    "    \n",
    "    return cosine_sim_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_city2 = cityFoodMain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_city2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = get_df('cities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = labelEncodeCity(cities)\n",
    "ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.sort_values('label_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fake\n",
    "food_user_f = createFoodUserDf()\n",
    "food_user_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_user = createFoodUserDf()\n",
    "food_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fake\n",
    "cosine_sim_foodf = simScore(food_city2, food_user_f)\n",
    "cosine_sim_foodf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_food = simScore(food_city2, food_user)\n",
    "cosine_sim_food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attractions City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to go into a function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_of_worship = ['place_of_worship', 'hindu_temple', 'church', 'mosque', 'synagogue']\n",
    "shopping = ['store', 'shopping_mall', 'clothing_store', 'electronics_store', 'grocery_or_supermarket', 'department_store']\n",
    "\n",
    "attractions_to_keep = ['amusement_park', 'museum', 'park', 'art_gallery', 'aquarium',\n",
    "                      'zoo', 'library', 'movie_theater', 'natural_feature'] + place_of_worship + shopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulls all attraction data from database. Will groupby each attraction type that I want to keep and count.\n",
    "# Returns: Each city with a count for the specified attractions\n",
    "\n",
    "def cityAttractionMain():\n",
    "    attractions = get_df('attractions')\n",
    "    attractions_split = split_types(attraction_df)\n",
    "    dummy = dummies(attractions_split)\n",
    "    by_city, all_attractions = attraction_count(dummy, attractions_split)\n",
    "    city_group = combineAttractionTypes(by_city)\n",
    "    city_attraction = labelEncodeAttraction(city_group)\n",
    "    clean_city_attraction, city_attraction = cleanCityAttraction(city_attraction)\n",
    "    \n",
    "    return clean_city_attraction, city_attraction\n",
    "\n",
    "def split_types(df):\n",
    "    df['split_types'] = [ast.literal_eval(x) for x in df.types]\n",
    "    df['split_types_str'] = [','.join(x) for x in df.split_types]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def dummies(df):\n",
    "    dummies = df.split_types_str.str.get_dummies(sep=',')\n",
    "\n",
    "    return dummies\n",
    "\n",
    "\n",
    "def attraction_count(dummies_df, all_attractions_df):\n",
    "\n",
    "    all_attractions_df = pd.concat([all_attractions_df, dummies_df], axis=1)\n",
    "    type_col_names = attractions_to_keep\n",
    "    type_col_names.extend(['country', 'city', 'id'])\n",
    "    attraction_count = all_attractions_df[type_col_names].groupby(['country', 'city', 'id']).sum()\n",
    "    \n",
    "    return attraction_count, all_attractions_df\n",
    "\n",
    "def combineAttractionTypes(city_group):\n",
    "    city_group['place_of_worship2'] = city_group['place_of_worship'] + city_group['hindu_temple'] + city_group['church'] + city_group['mosque'] + city_group['synagogue']\n",
    "    city_group['store2'] = city_group['store'] + city_group['shopping_mall'] + city_group['clothing_store'] + city_group['electronics_store'] + city_group['grocery_or_supermarket'] + city_group['department_store']\n",
    "    \n",
    "    city_group.rename(columns={\"place_of_worship2\" : 'place_of_worship', 'store2': 'shop', \"place_of_worship\" : 'place_of_worship5',}, inplace=True)\n",
    "    \n",
    "    city_clean = city_group[['amusement_park', 'art_gallery', 'aquarium', 'library', 'movie_theater',\n",
    "                              'museum', 'natural_feature', 'park', 'place_of_worship', 'shop', 'zoo']].copy()\n",
    "    \n",
    "    return city_clean\n",
    "\n",
    "\n",
    "def labelEncodeAttraction(city_attraction):\n",
    "    le = buildLabelEncoder()\n",
    "    city_attraction.reset_index(inplace=True)\n",
    "    city_attraction['label_id'] = le.transform(city_attraction.city)\n",
    "    \n",
    "    return city_attraction\n",
    "\n",
    "def cleanCityAttraction(city_attraction):\n",
    "    city_attraction.sort_values('label_id', inplace=True)\n",
    "    #city_attraction.reset_index(inplace=True)\n",
    "    city_attraction.set_index('label_id', inplace=True)\n",
    "    city_attraction.drop(columns=['id'], inplace=True)\n",
    "    city_attraction_clean = city_attraction.drop(columns=['city', 'country'])\n",
    "    \n",
    "    return city_attraction_clean, city_attraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_attraction, city_attraction_with_country = cityAttractionMain(attractions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_attraction_with_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attractions User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pulls from survey table and selects only attraction colummns\n",
    "def createAttractionUserDf():\n",
    "    survey = get_df('survey_response')\n",
    "    #survey = total.copy()\n",
    "    user_attraction = survey[['amusement_park', 'art_gallery', 'aquarium', 'library', 'movie_theater',\n",
    "                              'museum', 'natural_feature', 'park', 'place_of_worship', 'shop', 'zoo']]\n",
    "    return user_attraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake\n",
    "user_attractionf = createAttractionUserDf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_attraction = createAttractionUserDf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_attraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_attraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "city_attraction_with_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake\n",
    "cosine_sim_attractionf = simScore(city_attraction, user_attractionf)\n",
    "\n",
    "cosine_sim_attractionf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cosine_sim_attraction = simScore(city_attraction, user_attraction)\n",
    "\n",
    "cosine_sim_attraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim_food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UserxCity matrix sim score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This melts the cosine sim matrix that is userXcity to create my dataset where every userxcity combo is there\n",
    "# Start with the cosine_food\n",
    "# Could maybe pull out first couple lines and create own function...\n",
    "\n",
    "# Survey response data\n",
    "\n",
    "def createUserCitySimMatrix(cosine_sim_food, cosine_sim_attraction, food_new=food_new):\n",
    "    cosine_food = cosine_sim_food.reset_index()\n",
    "    cos_melt = cosine_food.melt(id_vars=['index'], value_name=\"food_sim\", var_name = \"city_id\")\n",
    "    cos_melt.rename(columns={'index': 'user'}, inplace=True)\n",
    "    cos_melt['city_id'] = cos_melt['city_id'].astype(int)\n",
    "    \n",
    "    city_dict = dict(zip(food_new['label_id'], food_new['city']))\n",
    "    \n",
    "    cos_melt['city'] = cos_melt['city_id'].map(city_dict)\n",
    "    \n",
    "    matrix_full = addAttractionSimMatrix(cos_melt, cosine_sim_attraction)\n",
    "\n",
    "    return matrix_full\n",
    "\n",
    "\n",
    "# melts attraction cosine matrix and then merge \n",
    "def addAttractionSimMatrix(user_city_matrix, cosine_sim_attraction):\n",
    "    cosine_attraction = cosine_sim_attraction.reset_index()\n",
    "    cos_melt = cosine_attraction.melt(id_vars=['index'], value_name=\"attraction_sim\", var_name = \"city_id\")\n",
    "    cos_melt['city_id'] = cos_melt['city_id'].astype(int)\n",
    "    \n",
    "    sim_matrix = pd.merge(right=user_city_matrix, left=cos_melt, right_on=['user', 'city_id'], left_on=['index', 'city_id'])\n",
    "    \n",
    "    final_matrix = addSumColumn(sim_matrix)\n",
    "    \n",
    "    return final_matrix\n",
    "\n",
    "def addSumColumn(sim_score_matrix):\n",
    "        \n",
    "    sim_score_matrix['sum'] = sim_score_matrix['food_sim'] + sim_score_matrix['attraction_sim']\n",
    "    clean = cleanMatrix(sim_score_matrix)\n",
    "    \n",
    "    return clean\n",
    "\n",
    "def cleanMatrix(matrix):\n",
    "    \n",
    "    matrix.drop(columns=['index'], inplace=True)\n",
    "    clean = matrix[['user', 'city_id', 'city', 'food_sim', 'attraction_sim', 'sum']]\n",
    "    clean.set_index(['user', 'city'], inplace=True)\n",
    "    \n",
    "    return clean\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survey response data\n",
    "\n",
    "# This handles top 5 favorite cities\n",
    "\n",
    "def createSimMatrixMain(table_name, cosine_sim_food, cosine_sim_attraction):\n",
    "    \n",
    "    top_city_melt = addTopCity(table_name)\n",
    "    top_city_no_na = dropNullRankCity(top_city_melt)\n",
    "    # need to call to create cosine_sim_food\n",
    "    \n",
    "    #Commented out for fake user\n",
    "    sim_df = createUserCitySimMatrix(cosine_sim_food, cosine_sim_attraction)\n",
    "    \n",
    "    sim_matrix_ready = mergeRanktoMatrix(sim_df, top_city_no_na)\n",
    "    \n",
    "    \n",
    "    return sim_matrix_ready\n",
    "\n",
    "\n",
    "def addTopCity(table_name):\n",
    "    survey = get_df(table_name)\n",
    "\n",
    "    top_city = survey[['favorite_city_one', 'favorite_city_two', 'favorite_city_three', 'favorite_city_four', 'favorite_city_five']].copy()\n",
    "    \n",
    "    top_city.reset_index(inplace=True)\n",
    "    top_city.rename(columns={'index': 'user'}, inplace=True)\n",
    "    top_city = top_city.replace({'': np.nan})\n",
    "    top_city_melt = top_city.melt(id_vars=['user'])\n",
    "    \n",
    "    top_city_melt['rank'] = top_city_melt.apply(rank_from_col,axis=1)\n",
    "\n",
    "\n",
    "    return top_city_melt\n",
    "\n",
    "\n",
    "def rank_from_col(x):\n",
    "    if x.variable=='favorite_city_one':\n",
    "       return 1\n",
    "    elif x.variable=='favorite_city_two':\n",
    "       return 1\n",
    "    elif x.variable=='favorite_city_three':\n",
    "       return 1\n",
    "    elif x.variable=='favorite_city_four':\n",
    "       return 1\n",
    "    elif x.variable=='favorite_city_five':\n",
    "       return 1\n",
    "    elif x.value == 'None':\n",
    "        return 0 \n",
    "    \n",
    "#Drops city ranks with Null values as city\n",
    "#Sets index\n",
    "def dropNullRankCity(top_city_melt):\n",
    "    top_city_no_na = top_city_melt.dropna().copy()\n",
    "    top_city_no_na.rename(columns={'value':'city'}, inplace=True)\n",
    "    top_city_no_na.set_index(['user', 'city'], inplace=True)\n",
    "    \n",
    "    return top_city_no_na\n",
    "\n",
    "\n",
    "\n",
    "def mergeRanktoMatrix(sim_df, rank_df):\n",
    "    \n",
    "    sim_matrix = pd.merge(left=sim_df, right=rank_df[['rank']], left_index=True, right_index=True, how='left')\n",
    "    sim_matrix.fillna(0, inplace=True)\n",
    "    sim_matrix.sort_values('user', inplace=True)\n",
    "    sim_matrix.set_index('city_id', append=True, inplace=True)\n",
    "\n",
    "    return sim_matrix\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work = createUserCitySimMatrix(cosine_sim_food, cosine_sim_attraction)\n",
    "work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fake\n",
    "\n",
    "work_fake = createUserCitySimMatrix(cosine_sim_foodf, cosine_sim_attractionf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fake\n",
    "work_fake.sort_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fake\n",
    "sim_fake = work_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might want to add this. It will sort by each user group by the top sum score\n",
    "\n",
    "#ordered_sum = sim_score_rank.sort_values('sum', ascending=False).sort_index(level='user', sort_remaining=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmmfix2 = createSimMatrixMain('survey_response', cosine_sim_food, cosine_sim_attraction)\n",
    "hmmfix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey Response transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformUserInput(table_name):\n",
    "    survey = get_df(table_name)\n",
    "    survey.drop(columns=[''], inplace=True)\n",
    "    nationality_dict = {'Australia': 1, 'Canada': 2, 'China': 3, 'Finland': 4, 'Honduras': 5,\n",
    "              'India': 6, 'Israel': 7, 'Japan': 8, 'Mexico': 9, 'Pakistan': 10, 'Philippines': 11, 'United States': 12}\n",
    "\n",
    "    survey.nationality = survey.nationality.map(nationality_dict)\n",
    "    survey = survey.replace({'': 'Zx'})\n",
    "    survey = encodeTopCity(survey)\n",
    "    survey = survey.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    finished = userDemographicDummy(survey)\n",
    "    \n",
    "    return finished\n",
    "\n",
    "\n",
    "\n",
    "def encodeTopCity(user_response):\n",
    "    \n",
    "    le = buildLabelEncoder()\n",
    "    user_response['one'] = le.transform(user_response['favorite_city_one'])\n",
    "    user_response['two'] = le.transform(user_response['favorite_city_two'])\n",
    "    user_response['three'] = le.transform(user_response['favorite_city_three'])\n",
    "    user_response['four'] = le.transform(user_response['favorite_city_four'])\n",
    "    user_response['five'] = le.transform(user_response['favorite_city_five'])\n",
    "    \n",
    "    return user_response\n",
    "\n",
    "\n",
    "def userDemographicDummy(user_response):\n",
    "    \n",
    "    ready = user_response.drop(columns=['favorite_city_one', 'favorite_city_two', 'favorite_city_three',\n",
    "                                          'favorite_city_four', 'favorite_city_five'])\n",
    "    dummy = pd.get_dummies(ready)\n",
    "    \n",
    "    return dummy\n",
    "\n",
    "\n",
    "def addContinent(city_df):\n",
    "    continents = {\n",
    "    'NA': 'North America',\n",
    "    'SA': 'South America', \n",
    "    'AS': 'Asia',\n",
    "    'OC': 'Australia',\n",
    "    'AF': 'Africa',\n",
    "    'EU': 'Europe'\n",
    "}\n",
    "    \n",
    "    city_df['continent'] = [continents[country_alpha2_to_continent_code(country_name_to_country_alpha2(country))] for country in city_df['country']]\n",
    "    city_df.set_index(['city', 'country'], append=True, inplace=True)\n",
    "    \n",
    "    return city_df\n",
    "\n",
    "def dummyContinent(city_df):\n",
    "    \n",
    "    city_dummy = pd.get_dummies(city_df)\n",
    "    \n",
    "    return city_dummy\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = get_df('survey_response')\n",
    "ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished = transformUserInput('survey_response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fake\n",
    "fake_survey_finished = pd.get_dummies(survey_fake)\n",
    "fake_survey_finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food and Attraction City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is not merging on label_id it is merging on id. WHY DO I HAVE ID\n",
    "def mergeAttractionFood(attraction_df, food_df):\n",
    "    \n",
    "    city = pd.merge(left = attraction_df, right = food_df, left_index = True, right_index=True)\n",
    "    \n",
    "    return city\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startToEnd():\n",
    "    \n",
    "    food_city = cityFoodMain()\n",
    "    food_user = createFoodUserDf()\n",
    "    cosine_sim_food = simScore(food_city, food_user)\n",
    "    \n",
    "    city_attraction, city_attraction_with_country = cityAttractionMain(attractions)\n",
    "    user_attraction = createAttractionUserDf()    \n",
    "    cosine_sim_attraction = simScore(city_attraction, user_attraction)\n",
    "    \n",
    "    design_matrix_sim = createUserCitySimMatrix(cosine_sim_food, cosine_sim_attraction)\n",
    "    \n",
    "    survey_clean = transformUserInput('survey_response')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_city2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_attraction_with_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = mergeAttractionFood(city_attraction_with_country, food_city2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df2 = addContinent(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df2_dummy = dummyContinent(city_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df2_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combing all data to get userxcity raw input and sim scores  \n",
    "\n",
    "all food and attraction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userCityCreate(survey_df, city_df):\n",
    "    \n",
    "    \n",
    "    reindex_survey = survey_df.reset_index()\n",
    "    reindex_city = city_df.reset_index()\n",
    "    reindex_city = reindex_city.add_suffix('_city')\n",
    "    reindex_survey = reindex_survey.add_suffix('_user')\n",
    "    reindex_city['key'] = 1\n",
    "    reindex_survey['key'] = 1\n",
    "    \n",
    "    full = pd.merge(reindex_city , reindex_survey, on='key').drop('key',axis=1)\n",
    "    \n",
    "    raw_inputs_matrix = cleanUserCityMatrix(full)\n",
    "\n",
    "    return raw_inputs_matrix\n",
    "\n",
    "def cleanUserCityMatrix(matrix):\n",
    "    \n",
    "    matrix.rename(columns={'label_id_city': 'city_id', 'city_city': 'city', 'index_user': 'user'}, inplace=True)\n",
    "    matrix.drop(columns=['country_city'], inplace=True)\n",
    "    matrix.set_index(['user', 'city', 'city_id'], inplace=True)\n",
    "    matrix.sort_index(level=0, inplace=True)\n",
    "\n",
    "    return matrix\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalMerge(raw_df, sim_score_df):\n",
    "    full_matrix = pd.merge(left= raw_df, right= sim_score_df, right_index=True, left_index=True)\n",
    "    full_matrix.sort_index(level=0, inplace=True)\n",
    "\n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "done = userCityCreate(finished, city_df2)\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_dummy = userCityCreate(finished, city_df2_dummy)\n",
    "done_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_dummy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fake\n",
    "\n",
    "done_fake2 = userCityCreate(fake_survey_finished, city4)\n",
    "done_fake2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake\n",
    "done_fake2.set_index('user', append=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake\n",
    "fake_survey_finished.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmmfix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished = finalMerge(done_dummy, hmmfix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished.sort_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finished.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake\n",
    "final = finalMerge(done_fake2, sim_matrix_fake)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final = final.reorder_levels(['user','city','city_id'])\n",
    "final.sort_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished.to_csv(r\"/Users/tristannisbet/Documents/SM/Dataframe/new/users_design_matrix_cont1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real_data = pd.read_csv('/Users/tristannisbet/Documents/SM/Dataframe/new/all_city_data.csv')\n",
    "real_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data_n = pd.read_csv('/Users/tristannisbet/Documents/SM/Dataframe/new/500_users_noise.csv')\n",
    "fake_data_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([fake_data_n, real_data], axis=0)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.rename(columns={'1': 'food_one', '2': 'food_two', '3': 'food_three', '4': 'food_four'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake user data Demographic questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationality_dict = {1: 'Australia', 2:'Canada', 3:'China', 4:'Finland', 5:'Honduras',\n",
    "              6:'India', 7:'Israel', 8:'Japan', 9:'Mexico', 10:'Pakistan', 11:'Philippines', 12:'United States'}\n",
    "\n",
    "gender_dict = {1: 'Male', 2: 'Female'}\n",
    "\n",
    "age_dict = {1 : '15-25', 2: '26-40', 3: '41-55', 4: '55+'}\n",
    "\n",
    "random_gender = [\"Male\", 'Female']\n",
    "random_age = ['15-25', '26-40', '41-55', '55+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_fake = total.drop(columns=['city', 'label_id', 'country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_fake['nationality'] = np.random.randint(0,12, len(survey_fake))\n",
    "\n",
    "survey_fake['gender'] = np.random.choice(random_gender, size=len(survey_fake))\n",
    "survey_fake['age'] = np.random.choice(random_age, size=len(survey_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_fake['one'] = np.random.randint(0,137, len(survey_fake))\n",
    "survey_fake['two'] = np.random.randint(0,137, len(survey_fake))\n",
    "survey_fake['three'] = np.random.randint(0,137, len(survey_fake))\n",
    "survey_fake['four'] = np.random.randint(0,137, len(survey_fake))\n",
    "survey_fake['five'] = np.random.randint(0,137, len(survey_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_fake.reset_index(inplace=True)\n",
    "survey_fake.rename(columns={'index': 'user'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fake = survey_fake[['user', 'one', 'two', 'three', 'four', 'five']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fake_melt = top_fake.melt(id_vars=['user'])\n",
    "    \n",
    "top_fake_melt['rank'] = top_fake_melt.apply(rank_from_col2,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "def rank_from_col2(x):\n",
    "    if x.variable=='one':\n",
    "       return 5\n",
    "    elif x.variable=='two':\n",
    "       return 4\n",
    "    elif x.variable=='three':\n",
    "       return 3\n",
    "    elif x.variable=='four':\n",
    "       return 2\n",
    "    elif x.variable=='five':\n",
    "       return 1\n",
    "    elif x.value == 'None':\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fake_melt.rename(columns={'value':'city_id'}, inplace=True)\n",
    "top_fake_melt.set_index(['user', 'city_id'], inplace=True)\n",
    "top_fake_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_fake.reset_index(level=1, inplace=True)\n",
    "work_fake.set_index('city_id', append=True, inplace=True)\n",
    "work_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_fake = pd.merge(left=work_fake, right=top_fake_melt[['rank']], left_index=True, right_index=True, how='left')\n",
    "#sim_matrix.fillna(0, inplace=True)\n",
    "#sim_matrix.sort_values('user', inplace=True)\n",
    "#sim_matrix.set_index('city_id', append=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_fake.drop(columns=['rank_x'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix_fake.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_top_city_fake(test_user):\n",
    "    possible_cities = test_user['city_id'].head(50).values.tolist()\n",
    "    sampled_list = random.sample(possible_cities, 5)\n",
    "    test_user.loc[test_user.city_id == sampled_list[0], \"rank\"] = 5\n",
    "    test_user.loc[test_user.city_id == sampled_list[1], \"rank\"] = 4\n",
    "    test_user.loc[test_user.city_id == sampled_list[2], \"rank\"] = 3\n",
    "    test_user.loc[test_user.city_id == sampled_list[3], \"rank\"] = 2\n",
    "    test_user.loc[test_user.city_id == sampled_list[4], \"rank\"] = 1\n",
    "    \n",
    "    return test_user\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_fake['rank'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_fake.groupby('user').apply(add_top_city_fake) \n",
    "\n",
    "#df.groupby('columnName').apply(myFunction, ('arg1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(sim_fake['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_user = sim_fake.xs(0, level='user', drop_level=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user.sort_values('sum', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_city = test_user['city_id'].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_cities = test_user['city_id'].head(50).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_list = random.sample(possible_cities, 5)\n",
    "sampled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for u in sampled_list:\n",
    "    print(u)\n",
    "    test_user[test_use['city_id'] == u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user['rank'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok2 = add_top_city_fake(test_user)\n",
    "ok2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok2[ok2['rank'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(test_user['rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user.loc[test_user.city_id == 69, \"rank\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user[test_user['rank'] == 1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmmfix2[hmmfix2['rank'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
